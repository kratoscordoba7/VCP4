{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector de matriculas P4 游땕"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import csv\n",
    "import pytesseract\n",
    "import math\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo usando easyOCR para la deteccion de matriculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargamos el modelo YOLO para detecci칩n de veh칤culos y personas\n",
    "detection_model = YOLO('models/yolov8n.pt')\n",
    "\n",
    "# Cargamos el modelo YOLO preentrenado para detectar matr칤culas\n",
    "license_plate_model = YOLO('models/best.pt')\n",
    "\n",
    "# Clases de inter칠s (personas y veh칤culos)\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "# Inicializamos el lector de EasyOCR\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "# Ruta del video\n",
    "video_path = 'media/video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Inicializamos el archivo CSV\n",
    "csv_file = open(\"data/detected_objects_easyOCR.csv\", mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['frame', 'object_type', 'confidence', 'tracking_id', 'x1', 'y1', 'x2', 'y2', 'license_plate', 'plate_confidence', 'direction'])\n",
    "\n",
    "# Inicializamos el objeto para grabar el video con los resultados\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('media/output_video_easyOCR.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "frame_count = 0\n",
    "directions = {\"left\": 0, \"right\": 0, \"up\": 0, \"down\": 0}  # Contadores de direcci칩n\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break  # Salimos del bucle si se acaba el video\n",
    "\n",
    "    frame_count += 1\n",
    "    detection_results = detection_model(img, stream=True)  # Detecci칩n de veh칤culos y personas\n",
    "\n",
    "    # Procesamos los resultados de detecci칩n de YOLO\n",
    "    for r in detection_results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            # Tomamos las coordenadas del contenedor\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100  # Confianza\n",
    "            cls = int(box.cls[0])  # 칈ndice de clase\n",
    "\n",
    "            if cls < len(classNames):\n",
    "                class_name = classNames[cls]\n",
    "\n",
    "                # Anonimizamos las personas\n",
    "                if class_name == \"person\":\n",
    "\n",
    "                    # Aplicamos un desenfoque a la regi칩n de la persona\n",
    "                    person_roi = img[y1:y2, x1:x2]\n",
    "                    blurred_person = cv2.GaussianBlur(person_roi, (51, 51), 0)\n",
    "                    img[y1:y2, x1:x2] = blurred_person\n",
    "\n",
    "                    # Detectamos la direcci칩n de la persona\n",
    "                    direction = \"left\" if x2 < img.shape[1] // 2 else \"right\"\n",
    "                    directions[direction] += 1\n",
    "\n",
    "                elif class_name in [\"car\", \"motorbike\", \"bus\", \"truck\"]:\n",
    "                    direction = \"left\" if x2 < img.shape[1] // 2 else \"right\"\n",
    "                    directions[direction] += 1\n",
    "\n",
    "                # Seguimiento (si est치 disponible)\n",
    "                tracking_id = box.track_id if hasattr(box, 'track_id') else None\n",
    "\n",
    "                # Dibujamos el rect치ngulo de la detecci칩n\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f\"{class_name} {confidence:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                # Si es un veh칤culo, aplicamos el modelo de matr칤culas\n",
    "                plate_text = \"\"\n",
    "                if class_name in [\"car\", \"motorbike\", \"bus\", \"truck\"]:\n",
    "\n",
    "                    img_cropped = img[y1:y2, x1:x2] # Nos quedamos con la zona de region del vehiculo ROI\n",
    "\n",
    "                    if img_cropped.size > 0:\n",
    "                        # Detectamos la matr칤cula con el modelo entrenado para matr칤culas\n",
    "                        license_plate_results = license_plate_model(img_cropped, stream=True)\n",
    "\n",
    "                        # Procesamos el generador directamente\n",
    "                        for plate in license_plate_results:\n",
    "                            plate_boxes = plate.boxes\n",
    "                            for plate_box in plate_boxes:\n",
    "                                # Extraemos las coordenadas de la matr칤cula\n",
    "                                px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                                img_plate_cropped = img_cropped[py1:py2, px1:px2]\n",
    "                                \n",
    "                                # Leemos el texto de la matr칤cula usando EasyOCR\n",
    "                                result = reader.readtext(img_plate_cropped, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "                                \n",
    "                                # Procesamos el texto detectado\n",
    "                                if len(result) >= 1:\n",
    "                                    plate_text = re.sub(r'[^A-Za-z0-9]', '', result[0][1]).strip()  # Limpiamos el texto\n",
    "\n",
    "                                # Dibujamos el texto de la matr칤cula en la imagen\n",
    "                                if plate_text:\n",
    "                                    cv2.putText(img, plate_text, (x1, y2 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                                    print(\"Matr칤cula detectada:\", plate_text)\n",
    "                                else:\n",
    "                                    print(\"No se detect칩 matr칤cula.\")\n",
    "\n",
    "                # Escribimos los datos en el archivo CSV\n",
    "                csv_writer.writerow([frame_count, class_name, confidence, tracking_id, x1, y1, x2, y2, plate_text, confidence, direction])\n",
    "\n",
    "    # Guardamos el frame procesado en el video de salida\n",
    "    out.write(img)\n",
    "\n",
    "    # Mostramos el video con las detecciones\n",
    "    cv2.imshow('Detector de personas y veh칤culos', img)\n",
    "\n",
    "    # Salimos si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos los recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Imprimimos el conteo de direcciones\n",
    "print(\"Direcciones detectadas:\")\n",
    "for direction, count in directions.items():\n",
    "    print(f\"{direction}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final:\n",
    "\n",
    "left: 1510,\n",
    "right: 1175,\n",
    "up: 0,\n",
    "down: 0,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver el modelo usando easyOCR para la interpretacion de los caracteres funciona relativamente bien en este caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro posible modelo usando pytesseract para la deteccion de matriculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos la ruta de Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "\n",
    "# Cargamos el modelo YOLO para detecci칩n de veh칤culos y personas\n",
    "detection_model = YOLO('models/yolov8n.pt')\n",
    "\n",
    "# Cargamos el modelo YOLO preentrenado para detectar matr칤culas\n",
    "license_plate_model = YOLO('models/modelo.pt')\n",
    "\n",
    "# Clases de inter칠s (personas y veh칤culos)\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "# Ruta del video\n",
    "video_path = 'media/video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Inicializamos el archivo CSV a crear\n",
    "csv_file = open(\"data/detected_objects_pytesseract.csv\", mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['frame', 'object_type', 'confidence', 'tracking_id', 'x1', 'y1', 'x2', 'y2', 'license_plate', 'plate_confidence', 'direction'])\n",
    "\n",
    "# Inicializamos el objeto para grabar el video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('media/output_video_pytesseract.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "frame_count = 0\n",
    "directions = {\"left\": 0, \"right\": 0, \"up\": 0, \"down\": 0}  # Contadores de direccion\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break  # Salimos del bucle si se acaba el video\n",
    "\n",
    "    frame_count += 1\n",
    "    detection_results = detection_model(img, stream=True)  # Detecci칩n de veh칤culos y personas\n",
    "\n",
    "    # Procesamos los resultados de detecci칩n de YOLO\n",
    "    for r in detection_results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # Tomamos las coordenadas del contenedor\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100  # Confianza\n",
    "            cls = int(box.cls[0])  # 칈ndice de clase\n",
    "\n",
    "            if cls < len(classNames):\n",
    "                class_name = classNames[cls]\n",
    "\n",
    "                # Anonimizar las personas\n",
    "                if class_name == \"person\":\n",
    "                    # Aplicamos un desenfoque a la regi칩n de la persona\n",
    "                    person_roi = img[y1:y2, x1:x2]\n",
    "                    blurred_person = cv2.GaussianBlur(person_roi, (51, 51), 0)\n",
    "                    img[y1:y2, x1:x2] = blurred_person\n",
    "                    direction = \"left\" if x2 < img.shape[1] // 2 else \"right\"\n",
    "                    directions[direction] += 1\n",
    "\n",
    "                elif class_name in [\"car\", \"motorbike\", \"bus\", \"truck\"]:\n",
    "                    direction = \"left\" if x2 < img.shape[1] // 2 else \"right\"\n",
    "                    directions[direction] += 1\n",
    "\n",
    "                # Seguimiento (si est치 disponible)\n",
    "                tracking_id = box.track_id if hasattr(box, 'track_id') else None\n",
    "\n",
    "                # Dibujamos el rect치ngulo de la detecci칩n\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f\"{class_name} {confidence:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                # Si es un veh칤culo, aplicamos el modelo de matr칤culas\n",
    "                plate_text = \"\"\n",
    "                if class_name in [\"car\", \"motorbike\", \"bus\", \"truck\"]:\n",
    "                    \n",
    "                    img_cropped = img[y1:y2, x1:x2] # Nos quedamos con los pixeles reconocidos como vehiculo ROI\n",
    "\n",
    "                    if img_cropped.size > 0:\n",
    "                        # Aplicamos el modelo para detectar matr칤culas\n",
    "                        license_plate_results = license_plate_model(img_cropped, stream=True)\n",
    "\n",
    "                        # Procesamos el generador directamente\n",
    "                        for plate in license_plate_results:\n",
    "                            plate_boxes = plate.boxes\n",
    "                            for plate_box in plate_boxes:\n",
    "                                # Extraemos las coordenadas de la matr칤cula\n",
    "                                px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                                img_plate_cropped = img_cropped[py1:py2, px1:px2]\n",
    "                                \n",
    "                                # Leemos el texto de la matr칤cula usando pytesseract\n",
    "                                text = pytesseract.image_to_string(img_plate_cropped, config='--psm 8 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "                                plate_text = re.sub(r'[^A-Za-z0-9]', '', text).strip()  # Limpiamos el texto\n",
    "\n",
    "                                # Dibujamos el texto de la matr칤cula en la imagen\n",
    "                                if plate_text:\n",
    "                                    cv2.putText(img, plate_text, (x1, y2 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                                    print(\"Matr칤cula detectada:\", plate_text)\n",
    "                                else:\n",
    "                                    print(\"No se detect칩 matr칤cula.\")\n",
    "\n",
    "                # Escribimos los datos en el archivo CSV\n",
    "                csv_writer.writerow([frame_count, class_name, confidence, tracking_id, x1, y1, x2, y2, plate_text, confidence, direction])\n",
    "\n",
    "    # Guardamos el frame procesado en el video de salida\n",
    "    out.write(img)\n",
    "\n",
    "    # Mostramos el video con las detecciones\n",
    "    cv2.imshow('Detector de personas y veh칤culos', img)\n",
    "\n",
    "    # Salimos si se presiona \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Direcciones detectadas:\")\n",
    "for direction, count in directions.items():\n",
    "    print(f\"{direction}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final:\n",
    "\n",
    "left: 1510,\n",
    "right: 1175,\n",
    "up: 0,\n",
    "down: 0,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver este 2 modelo funciona como el anterior aunque falla mas en seguir las matriculas, y predecirlas sin fallar de manera correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos planteamos la estrategia de dividir la deteccion en dos partes primero, dividimos el 1 modelo es el general de yolo para poder detectar personas, y el segundo es un modelo especifico para matriculas, y utilizamos easyOCR en el primero y pyteserrecact en el segundo. Como podemos observar la libreria EasyOCR funciona mucho mejor en este caso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
