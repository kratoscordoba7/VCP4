{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de matriculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "from pytesseract import Output\n",
    "import easyocr\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 modelo posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = easyocr.Reader(['en']) # Inicializamos el lector de easyocr\n",
    "\n",
    "# Carga del modelo preentrenado YOLO (nano)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Etiqueta de las distintas clases relevantes \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "video_path = 'video.mp4'\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # Verificamos si hay una imagen válida\n",
    "    if ret:\n",
    "        # Reducimos la resolución de la imagen para mejorar la velocidad\n",
    "        img = cv2.resize(img, (640, 600))\n",
    "\n",
    "        # Seguimiento en tiempo real para clases relevantes (personas y vehículos)\n",
    "        results = model.track(img, persist=True, classes=[0, 1, 2, 3, 5, 7])\n",
    "\n",
    "        # Iteramos sobre cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Extraemos las coordenadas de la caja delimitadora\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                # Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "\n",
    "                # Nivel de confianza\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Clase detectada\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = classNames[cls] if cls < len(classNames) else \"unknown\"\n",
    "\n",
    "                color = (0, 255, 0) if cls == 0 else (0, 0, 255)  # Verde para personas, rojo para vehículos\n",
    "\n",
    "                # Dibujamos el contenedor y la etiqueta de clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(img, f\"{track_id} {class_name} {confidence:.2f}\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                # Si es una persona, tapamos la cara\n",
    "                if cls == 0: \n",
    "                    face_height = int((y2 - y1) * 0.4)  # Asumimos que la cara ocupa el 40% superior del cuerpo\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y1 + face_height), (0, 0, 0), -1)  # Rectángulo negro\n",
    "\n",
    "                # Si es un vehículo, intentar detectar la matrícula\n",
    "                if cls in [2, 3, 5, 7]: \n",
    "                    # Enfocamos en la parte baja del vehículo\n",
    "                    plate_img = img[int(y1 + (y2 - y1) * 0.6):y2, x1:x2]\n",
    "\n",
    "                    # Preprocesamos la imagen de la matrícula\n",
    "                    gray_plate_img = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "                    enhanced_plate_img = cv2.equalizeHist(gray_plate_img)  # Aumentamos el contraste\n",
    "                    _, binary_plate_img = cv2.threshold(enhanced_plate_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "                    # Detectamos el texto en la imagen de la matrícula\n",
    "                    plate_text = reader.readtext(binary_plate_img, detail=0)\n",
    "                    plate_text_str = ' '.join([text for text in plate_text if any(char.isalnum() for char in text)])\n",
    "\n",
    "                    # Mostramos el texto detectado en la imagen\n",
    "                    cv2.putText(img, plate_text_str.strip(), (x1, y2 + 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Detección y super seguimiento', img)\n",
    "    else:\n",
    "        break \n",
    "\n",
    "    # Salimos del bucle si se presiona ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 modelo posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño del video\n",
    "desired_size = (800, 500)\n",
    "\n",
    "model = YOLO('modelo.pt')  # Modelo de yolo preentrenado\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "def preprocess_plate(plate):\n",
    "    \"\"\"Preprocesar la imagen de la matrícula para mejorar la detección de texto.\"\"\"\n",
    "    gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "    # Aplicamos umbral adaptativo para resaltar caracteres\n",
    "    processed_plate = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    return processed_plate\n",
    "\n",
    "def show_image(window_name, image):\n",
    "    resized_image = cv2.resize(image, desired_size)\n",
    "    cv2.imshow(window_name, resized_image)\n",
    "\n",
    "# Leemos el video\n",
    "video_path = \"video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Verificamos si el video se abrió correctamente\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el video\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Si no se leen más cuadros, salimos\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detectamos matrículas con el modelo\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # Iteramos sobre cada detección en el resultado\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # Coordenadas del contenedor\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convertimos a valores enteros\n",
    "\n",
    "            # Extraemos solo la matrícula\n",
    "            plate = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Preprocesar la imagen de la matrícula\n",
    "            processed_plate = preprocess_plate(plate)\n",
    "\n",
    "            # Recuadro de la matrícula\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "            # Expresión regular para detectar la matrícula \"0000 AAA\"\n",
    "            plate_pattern = re.compile(r'^\\d{4}[A-Z]{3}$')\n",
    "\n",
    "            # Utilizamos pytesseract para la detección de texto en la imagen preprocesada\n",
    "            text = pytesseract.image_to_string(processed_plate, config='--psm 8', output_type=Output.STRING)\n",
    "\n",
    "            # Limpiamos el texto detectado\n",
    "            text = re.sub(r'[^A-Za-z0-9]', '', text).strip()\n",
    "\n",
    "            # Verificamos si el texto cumple con el formato de matrícula\n",
    "            if plate_pattern.match(text):\n",
    "                print(\"Matrícula detectada:\", text)\n",
    "            else:\n",
    "                print(\"Texto detectado (no coincide con patrón de matrícula):\", text)\n",
    "\n",
    "    # Mostramos el video\n",
    "    show_image(\"Super mega detector\", frame)\n",
    "\n",
    "    # Salimos si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar el video\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 posible modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargamos nuestro modelo YOLO preentrenado\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "classNames = [\"Super matricula\"]  # Clase de matrícula\n",
    "\n",
    "# Inicializa el lector de EasyOCR\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "# Ruta del video\n",
    "video_path = 'video.mp4'\n",
    "\n",
    "# Abrimos\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Salimos del bucle si se acaba el video\n",
    "\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Tomamos el contenedor\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            # Confianza\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "            print(\"Confianza: \", confidence)\n",
    "\n",
    "            # Clase\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Nombre de la clase: \", classNames[0])\n",
    "\n",
    "            # Dibujamos el contenedor\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, f\"{classNames[0]} {confidence}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Recortamos el área de interés (matrícula)\n",
    "            img_cropped = img[y1:y2, x1:x2]\n",
    "            if img_cropped.size > 0:\n",
    "                # Reconocimiento de una imagen\n",
    "                result = reader.readtext(img_cropped, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "                output = \"\"\n",
    "\n",
    "                if len(result) >= 1:\n",
    "                    first = result[0][1]\n",
    "                else:\n",
    "                    first = \"\"\n",
    "\n",
    "                if len(result) >= 2:\n",
    "                    second = result[1][1]\n",
    "                else:\n",
    "                    second = \"\"\n",
    "\n",
    "                if first.isnumeric():\n",
    "                    output = first + \" \" + second\n",
    "                else:\n",
    "                    output = second + \" \" + first\n",
    "\n",
    "                print(\"La matrícula detectada es:\", output)\n",
    "\n",
    "    cv2.imshow('Detector increible de Matriculas', img)\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro posible modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuramos la ruta de Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Cargamos nuestro modelo YOLO\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "classNames = ['Matricula'] \n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(\"video.mp4\")\n",
    "  \n",
    "while True:      \n",
    "    # Leemos fotograma por fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # Si hay una imagen válida\n",
    "    if ret:  \n",
    "        # Realiza inferencia en el fotograma\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Extraemos las coordenadas del contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Conviertimos a enteros\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # Recortamos la región de interés (ROI)\n",
    "                cropped = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Aplica reconocimiento de texto a la imagen recortada\n",
    "                text = pytesseract.image_to_string(cropped)\n",
    "\n",
    "                # Convierte el identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255 * 2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255 * 2\n",
    "                elif escala >= 255:\n",
    "                    R = 255\n",
    "                    G = escala - 255\n",
    "                    B = 0\n",
    "                else:\n",
    "                    R = escala\n",
    "                    G = 0\n",
    "                    B = 0\n",
    "\n",
    "                # Dibujamos el contenedor y el texto\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, text.strip(), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('Video matriculas', img)\n",
    "    \n",
    "    # Detenemos el video si se presiona ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
